\chapter{Related Work}\label{related-work}

A big, widely used, and mature language like Python has no lack of Static Analysis tools.
A big, widely used, and mature area like Machine Learning has no lack of people trying to
build tools to make writing code for it easier. In this chapter, a brief overview of the
many Static Analysis tools developed for Python code and the several approaches taken to
solve the problem of tensor shapes.

\section{Static Analysis in Python}

% {\inlinetodo{add note in the difficulty of knowing what is the theory
% behind some of the most widely used linters}}

In Table~\ref{relatedworktable}, a list of all analysis tools found in the literature
and libraries is given. The usage of a tool refers to how is the tool used by developers:
embedded in the python interpreter, used as a linter, or as a library that runs with the
code to analyse. The Analysis base of a tool refers to which is the theory behind the
tool, how it works underneath.
% The purpose of analysis tools are varied and broad in scope.

\begin{sidewaystable}[p]
\centering
\begin{threeparttable}
\begin{longtable}[]{|l|l|l|l|}
  \caption{Analysis tools for Python.
  }\label{relatedworktable}\tabularnewline
  \toprule
  Tool Name / Source & Usage & Analysis base & Purpose \tabularnewline
  \midrule
  \endhead
    \textcite{cannon_localized_2005}                     & Embeded & Type analysis           & Typecheking     \tabularnewline
    Pep8\tnote{0}                                        & Linter  & N/A                     & Code style analysis \tabularnewline
    Pyflakes\tnote{1}                                    & Linter  & N/A                     & Various checks  \tabularnewline
    Pylint \autocite{thenaultpylint}                     & Linter  & N/A                     & Various checks  \tabularnewline
    PyChecker \autocite{norwitzpychecker}                & Linter  & N/A                     & Various checks  \tabularnewline
    MyPy \autocite{lehtosalo2016mypy}                    & Linter  & Gradual Type Analysis   & Type checking   \tabularnewline
    Enforce\tnote{2}\tnote{+} (defunct)                  & Library & Gradual Type Analysis   & Type checking               \tabularnewline
    Sagitta\tnote{3}\tnote{+} (defunct)                  & Library & Type analysis           & Type checking               \tabularnewline
    StyPy \autocite{ortin_towards_2015}                  & Linter  & Novel                   & Type checking               \tabularnewline
    Lyra\tnote{4}                                        & Library & Abstract Interpretation & Various analyses (including Value Analysis) \tabularnewline
    Pytropos\tnote{5} (This Work)                        & Linter  & Abstract Interpretation & Value Analysis (specialised on tensor shapes) \tabularnewline
    PyType\tnote{6}                                      & Linter  & N/A                     & Type checking and inference \tabularnewline
    ICBD\tnote{7} (defunct)                              & Linter  & N/A                     & Type checking and inference \tabularnewline
    Pyre\tnote{8}                                        & Linter  & Abstract Interpretation & Type checking               \tabularnewline
    Nagini\tnote{9} \autocite{eilers_nagini_2018}        & Linter  & SMT (Viper)             & Verifier                    \tabularnewline
    Typpete\tnote{10} \autocite{hassan_maxsmt-based_2018} & Library & SMT                     & Type inference              \tabularnewline
    \textcite{fromherz_static_2018}\tnote{*}             & N/A     & Abstract Interpretation & Value Analysis | Verifier   \tabularnewline
    \textcite{monat_static_2018}\tnote{*}                & N/A     & Abstract Interpretation & Type Analysis               \tabularnewline
    PyAnnotate\tnote{+}\tnote{11}                        & Library & Gradual Type Analysis   & Type inference              \tabularnewline
    MonkeyType\tnote{+}\tnote{12}                        & Library & Gradual Type Analysis   & Type inference              \tabularnewline
  \bottomrule
\end{longtable}
\begin{tablenotes}
  \item[+] \footnotesize It is not an static analysis. It is a dynamic analysis.
  \item[*] Tool has not been made public.
  \item[0] Homepage: \url{https://pep8.readthedocs.io/}
  \item[1] Homepage: \url{https://pypi.org/project/pyflakes/}
  \item[2] Homepage: \url{https://github.com/RussBaz/enforce}
  \item[3] Homepage: \url{https://github.com/peterhil/sagitta}
  \item[4] Homepage: \url{https://github.com/caterinaurban/Lyra}
  \item[5] Homepage: \url{https://github.com/helq/pytropos}
  \item[6] Homepage: \url{https://github.com/google/pytype}
  \item[7] Homepage: \url{https://github.com/kmod/icbd}
  \item[8] Homepage: \url{https://github.com/facebook/pyre-check}
  \item[9] Homepage: \url{https://github.com/marcoeilers/nagini}
  \item[10] Homepage: \url{https://github.com/caterinaurban/Typpete}
  \item[11] Homepage: \url{https://github.com/dropbox/pyannotate}
  \item[12] Homepage: \url{https://github.com/Instagram/MonkeyType}
\end{tablenotes}
\end{threeparttable}
\end{sidewaystable}

\textcite{cannon_localized_2005} was the first (to our knowledge) to try to statically
infer and type check code in Python. His idea was to infer variables' types before
executing the code and use this knowledge to speed up the execution. He acknowledged that
the nature of Python makes type inference to be too weak. Thus, the complexity that the
project brought did not improve performance in equal measure and his work was never added
to Python. This work was prior to \textcite{siek_gradual_2006} Gradual Types, where the
developer can help the type checking algorithm to find and assert better types.

All linters' goal is to aid the developer by flagging code as faulty. What means for a
piece of code to be faulty varies from tool to tool. Pep8 checks for syntactic deviations
of the style guide, Pep 8\footnote{\url{https://www.python.org/dev/peps/pep-0008/}}.
Pyflakes, Pylint and PyChecker define a variety of checks for common scenarios where a
piece of code is known to fail, e.g.~undefined variables. MyPy, PyType and Pyre focus on
type checking optionally type-annotated code. Nagini focuses on verifying pieces of Python
code using the mature Viper \autocite{muller_viper_2016} infrastructure. Pytropos
objective is different from all the other available linters: Value Analysis.

Our work is closest to \textcite{fromherz_static_2018} as they focus on Value Analysis as
well. Fromherz et.~al focus is on building an Abstract Interpreter to verify Python code.
Our focus is not in verification but in the shape of Tensors. Their Abstract Interpreter
incorporates more capabilities than we do: exception handling and support for breaking
flow instructions. Unfortunately, they have not yet made their implementation public.

\section{Tensor Shape Analysis}

% {\inlinetodo{add idea from http://nlp.seas.harvard.edu/NamedTensor
% Alexander, who suggests building the libraries in a different way so we
% do not have some of the problems of working with nameless shapes}}
%
% {\inlinetodo{extend solutions described below with the new libraries you
% found, comment below}}
%  {2018.06.25} tensors papers and libraries
%  * (mypy-python) https://github.com/machinalis/mypy-data/tree/master/numpy-mypy
%  * (python (in java)) ariadne https://github.com/wala/ML (paper by dolby (weird name))
%  * (haskell) https://github.com/achirkin/easytensor
%  * (nopython) https://github.com/Diderot-Language/diderot (Diderot: a domain-specific language for portable parallel scientific visualization and image analysis)
%                                                           Chiw et al (2018) - Compiling Diderot
% \inlinetodo{there was one more paper to take into account. I don't recall its name but
% it was about a tool to check for the shape of tensors!!}

\subsection{Solutions in other languages}

We may think, If a type system is not expressive enough to capture the
shape of tensors, then we should just start writing code in a language
which does. We may write code in a language like Haskell or even C++,
which have very strong and expressive type systems (it is possible in
C++ to enforce the shape of the tensors with the use of templates and
constraints (C++20)).

In fact, solutions in other languages exist. For example,
\textcite{chen_typesafe_2017} type checks the shape of tensors
(operations) by restricting what can be constructed (via constraints in
the types of objects and functions). Chen's solution uses the powerful
type system of Scala (which runs over the JVM).
\textcite{eaton_statically_2006} does the same, although in an old
version of Haskell. Eaton's encoding of tensor shapes is awkward because
Haskell did not have, at the time, support for natural numbers at the
type level. Haskell also lacked on syntactic sugar for type functions.
\textcite{abe_simple_2015} implement type checking for matrices (aka,
tensors) in OCaml. The library detects the shape of the matrices at
compile time. \textcite{rakic_statically_2012} type check tensor shapes
(they call them matrices) with templates in C++. Templates are only
accessible at compile time, thus the RakiÄ‡ et al.~library type checks at
compile.

One recent effort to type check tensor shapes in Haskell is the library
\pycode|tensorflow-haskell-deptyped| written by
\textcite{elkin_haskell_2018}. The library is written as a wrapper
around the library port of TensorFlow for Haskell.
\pycode|tensorflow-haskell-deptyped| enforces at the type level how and
which results an operation between compatible tensors is to be performed.

A different path to take is to extend an existing type checking system,
like MyPy, and extend it with dependent types. Dependent types allow us
to carry information from the term level to the type level, i.e.~we can
encode information of our data (available only at runtime) into the type
system. Over this extended type system, we could implement some
restrictions to the operations applied to different types (this is, in
fact, the strategy taken in the library tensorflow-haskell-deptyped).

\subsection{Theoretical Solutions}\label{theoretical-solutions}

The problem of mismatched shapes is not new, in fact, it is so common
that it has appeared several times with similar solutions
\autocites{arnold_specifying_2010}{griffioen_type_2015}{rink_modeling_2018}{slepak_array-oriented_2014}{trojahner_dependently_2009}.
All solutions, though, are theoretical, they propose type systems which,
if they were to be implemented, could warranty type safety, i.e.~no
mismatching of tensor shapes could ever happen at runtime.

The following is a small discussion about the different solutions
proposed to type check tensors found in the literature\footnote{As a
  side note, it is interesting to notice how difficult is to communicate
  ideas in science. All the papers presented in this section hope to
  solve the same (or similar) problem, but they do not reference each
  other, which means that none of them knew what the others were doing.
  The principal reason for this, I think, it is because they all called
  the problem differently.}:

\begin{itemize}
\item
  \textcite{trojahner_dependently_2009}: A paper on type checking of
  arrays. They define all type restrictions using dependent types
  (something that no other paper does). The special keyword of this work
  is \enquote{array programming}.
\item
  \textcite{arnold_specifying_2010}: A paper focused on type checking of
  sparse \enquote{matrix} operations. They define a functional language
  that can be translated into a lower level language or machine code.
  They give a complete formalization of the algorithms and proofs of
  correctness in Isabelle. The special keyword of this work is
  \enquote{sparse matrix}.
\item
  \textcite{griffioen_type_2015}: A paper focused on type checking and
  inference of arrays in array programming and vector spaces. They
  define a special type system in which tensors are first class
  citizens. The algorithm used for type checking is
  \enquote{Unification} which allows them to infer the type shape of
  arrays. The special keyword of this work is \enquote{array
  programming}.
\item
  \textcite{slepak_array-oriented_2014}: A paper that tries to formalise
  array-oriented programming languages and extend them with unit-aware
  operations. Array-oriented programming languages are languages which
  base all their computations in arrays (like matlab), but they usually
  aren't formalised. The types of arrays not only carry information
  about their shape but also of the unit they carry. The special
  keywords of this work are \enquote{array-oriented programming} and
  \enquote{unit-aware computation}.
\item
  \textcite{rink_modeling_2018}: In this paper, Rink formalises a type
  system to type check the shape of tensors and defines a language to
  use with the type system. It is a custom type system which does not
  require of dependent types. The special keyword of this work is
  \enquote{tensor manipulation language}.
\end{itemize}
